{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhkQMwrapyVx"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/analiza-dokumentow/blob/main/16--cleaning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VImENKyPhMTa"
   },
   "source": [
    "## Znaki specjalne, nadmiarowe spacje, znaczniki HTML, inne jeżeli potrzeba\n",
    "\n",
    "## Czyszczenie danych\n",
    "* istotne z perspektywy uwydatnienia poszukiwanych informacji\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = '''Termin „post-truth” na tyle zyskał na znaczeniu w opisie rzeczywistości społeczno-politycznej, że w corocznym plebiscycie Oxford Dictionaries redaktorzy uznali go za słowo roku 2016. Argumentowano to m.in. tym, że termin „post-prawda”, używany coraz powszechniej w różnego rodzaju komentarzach politycznych i ważnych publikacjach, przestał mieć znaczenie peryferyjne, stając się terminem samodzielnym, niewymagającym dodatkowego wyjaśniania i definiowania.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nietrywialny przykład z języka polskiego\n",
    "\n",
    "* prof. Jan Kowalski obiecł zaliczenia w 1-szym terminie\n",
    "* Koń ciągnie\n",
    "* Nigdy więcej wojny!\n",
    "* Ala ma kota a kot ma mleko\n",
    "\n",
    "zdanie (ang. sentence) vs wypowiedź (ang. utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = \"Ala ma kota a kot ma mleko. Krzyś ma psa, kota, chomika, jaszczurkę i papugę.\"\n",
    "input_2 = \"Wiedźmin rzucił się w jej stronę, w skoku dobywając miecza.\"\n",
    "input_3 = \"Stale ucz się. Im więcej różnych rzeczy wiesz, tym lepiej. Czytaj techniczną książkę raz na kwartał. Nietechniczne też czytaj. Uczestnicz w kursach, odwiedzaj konferencje.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacja\n",
    "\n",
    "podzieleniu analizowanego tekstu na części ``tokeny``\n",
    "\n",
    "``ala``, ``ma``, ``kota``, ``a``, ``kot``, ``ma``, ``mleko``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default - space\n",
    "input_1.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(input_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni-Gram | Bi-Gram | Tri-Gram | N-Gram\n",
    "\n",
    "Ala ma kota a kot ma mleko\n",
    "\n",
    "```\n",
    "Uni-Gram (1-gram) Ala, ma, kota, a, kot, ma, mleko\n",
    "Bi-Gram (2-gram) Ala ma, ma kota, kota a, a kot, kot ma, ma mleko \n",
    "Tri-Gram (3-gram) Ala ma kota, ma kota a, kota a kot,  a kot ma, kot ma mleko \n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "list(ngrams(word_tokenize(input_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize('prof. Jan Kowalski obiecł zaliczenia w 1-szym terminie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja\n",
    "\n",
    "Upraszczanie do wspólnej wartości. \n",
    "\n",
    "```\n",
    "kot -> kot\n",
    "kota -> kot\n",
    "kotem -> kot\n",
    "jeden -> jeden\n",
    "jedna -> jeden\n",
    "jeden -> 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J60mV44H_AL-"
   },
   "source": [
    "## Stemming\n",
    "bazując na definicji z angielskiej wikipedii jest to proces polegający na wydobyciu z wybranego wyrazu tzw. rdzenia, a więc tej jego części, która jest odporna na odmiany przez przyimki, rodzaje itp.\n",
    "\n",
    "```\n",
    "Wiedźmin -> Wiedźmin\n",
    "rzucił -> rzucił\n",
    "się -> się \n",
    "w -> w \n",
    "jej -> je\n",
    "stronę -> stron\n",
    "w -> w \n",
    "skoku -> skok\n",
    "dobywając -> dobywa\n",
    "miecza -> miecz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoAe73Ct_Mei"
   },
   "source": [
    "## Lematyzacja\n",
    "\n",
    "pojęcie to jest bardzo podobne do powyższego, a oznacza sprowadzenie grupy wyrazów stanowiących odmianę danego zwrotu do wspólnej postaci, umożliwiającej traktowanie ich wszystkich jako te samo słowo.\n",
    "\n",
    "```\n",
    "Wiedźmin -> Wiedźmin\n",
    "rzucił -> rzuca\n",
    "się -> się \n",
    "w -> w \n",
    "jej -> jej\n",
    "stronę -> strona\n",
    "w -> w \n",
    "skoku -> skok\n",
    "dobywając -> dobywa\n",
    "miecza -> miecz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvaqQG0xj5w_"
   },
   "source": [
    "## Oczyszczanie | Przekształcanie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BOOKS = pd.read_pickle('var/books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS['content'][6][:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS['content'][6][-1800:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wolnelektury.pl/media/book/txt/dziady-dziady-widowisko-czesc-i.txt\n",
    "\n",
    "```\n",
    "-----\n",
    "Ta lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\n",
    "Wersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/dziady-dziady-widowisko-czesc-i.\n",
    "\n",
    "Utwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = '''\n",
    "Adam Mickiewicz\\r\\n\\r\\nDziady.\n",
    "\n",
    "ISBN 978-83-288-2972-5\n",
    "Widowisko, część I\\r\\n\\r\\n\\r\\n\\r\\n/ Prawa strona teatru — Dziewica w samotnym pokoju — na boku ksiąg mnóstwo, fortepiano, okno z lewej strony w pole; na prawej wielkie zwierciadło; świeca gasnąca na stole i księga rozłożona (romans Vale\n",
    "----- Ta lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\n",
    "Wersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/dziady-dziady-widowisko-czesc-i.\n",
    "\n",
    "Utwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WT2qseWj8OR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"^.*\\n\",\"\", text) \n",
    "    text = re.sub(r\"ISBN.*[1-9\\-]{16,20}\",\"\", text, flags=re.IGNORECASE) \n",
    "    \n",
    "    text = re.sub(u\"[ \\n]+\", \" \", text) # newlines -> spaces\n",
    "    text = re.sub(u\"[ \\r]+\", \" \", text) # \\r -> spaces\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"----- Ta lektura.*\",\"\", text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "assert ('\\n' not in preprocess_text(test_text))\n",
    "assert ('\\r' not in preprocess_text(test_text))\n",
    "assert ('  ' not in preprocess_text(test_text))\n",
    "assert ('Ta lektura,' not in preprocess_text(test_text))\n",
    "assert ('ISBN' not in preprocess_text(test_text))\n",
    "assert ('2972-5' not in preprocess_text(test_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "VLrSz4zRk-ob",
    "outputId": "1ac33858-8aeb-419e-e313-025ffdbb3d8b"
   },
   "outputs": [],
   "source": [
    "test_text = preprocess_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3oMZ2fwnIge"
   },
   "outputs": [],
   "source": [
    "def split_to_sentences(text):\n",
    "  return [re.sub(r\"^ \",\"\",l) for l in re.split('\\.|,|\\?|!|:', text)]\n",
    "\n",
    "assert(['hello world', \"Hello John\"] == split_to_sentences(\"hello world! Hello John\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4CjN7SjVeg"
   },
   "source": [
    "### interpunkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xWaegBkeh1TM",
    "outputId": "88bcbd8f-1731-48e2-f366-aeb35d48d7c7"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIxN8jAlifwT"
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5y_YgrCiloW"
   },
   "outputs": [],
   "source": [
    "assert(remove_punct(\"hello, world!\") == \"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYvEZdESxGjc"
   },
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZGWOBrhxeUm"
   },
   "outputs": [],
   "source": [
    "stop_words = (requests\n",
    "         .get('https://raw.githubusercontent.com/bieli/stopwords/master/polish.stopwords.txt')\n",
    "         .text\n",
    "         .split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjmr6VLHxi36",
    "outputId": "e2f02f0e-d480-4091-94b3-5ce9a5bcaf1f"
   },
   "outputs": [],
   "source": [
    "\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeCZwUwPxEUA"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "  return \" \".join([word for word in text.split(' ') if word not in stop_words])\n",
    "\n",
    "assert \"Cześć czołem\" == remove_stop_words(\"Cześć i czołem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS_gsLONit3p"
   },
   "outputs": [],
   "source": [
    "BOOKS['content_txt'] = (BOOKS.content\n",
    "                             .apply(preprocess_text)\n",
    "                             .apply(lambda s: s.lower())\n",
    "                             .apply(remove_stop_words)\n",
    "                             .apply(sent_tokenize)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(sentence):\n",
    "    sentence = remove_punct(sentence)\n",
    "    sentence.replace(\"—\", \"\")\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS['sentences_clean'] = BOOKS.content_txt.apply(lambda sentences: list(map(clean_sentences, sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMcwYFAzm2tC"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOKS[['author',  'sentences_clean']].explode('sentences_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3I0EIskoMAV"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOK_LINES.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "u9B0TQRFpVw2",
    "outputId": "40c299d8-b7d3-4327-9826-b92e883bf84b"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zK9ml_J4pkVF",
    "outputId": "2be4eacc-c2f4-4965-9814-52dbadf827dd"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES.groupby('author').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK1jmVyUp3HU"
   },
   "source": [
    "Duża różnica w elementach danej klasy!! Może mieć wpływ na rezultaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pWHWKiFpxWS"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES['words'] = BOOK_LINES.sentences_clean.apply(lambda s: len(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "PRVIqEdOsSXU",
    "outputId": "fd7c0d93-3b2a-493d-9a50-07b0391fe621"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES.groupby('author')['words'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSphnG-Bs5uN"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOK_LINES[BOOK_LINES['words'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9votvf7asmzG",
    "outputId": "91599880-89b8-45a8-f2f8-01d4d78952cc"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES.groupby('author')['words'].quantile(0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zJXtgj4vsom-",
    "outputId": "29238dcb-bfaa-4751-a20c-5b6908ad2198"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES.groupby('author')['words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_together = \" \".join(BOOK_LINES[BOOK_LINES.author == 'Mickiewicz'].sentences_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_LINES.to_pickle('var/books_lines.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width = 400, height = 400, \n",
    "                      background_color = 'black', \n",
    "                      min_font_size = 5,\n",
    "                      stop_words=stop_words,\n",
    "                      max_words=1000,\n",
    "                      collocations=False).generate(\"Ala ma kota a kot ma mleko\")\n",
    "\n",
    "plt.figure(figsize = (12, 12), facecolor = 'lavender')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 2) \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Eksploracyjna_analiza_dokumentów_tekstowych.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
