{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhkQMwrapyVx"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/analiza-dokumentow/blob/main/16--cleaning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VImENKyPhMTa"
   },
   "source": [
    "## Znaki specjalne, nadmiarowe spacje, znaczniki HTML, inne jeżeli potrzeba\n",
    "\n",
    "## Czyszczenie danych\n",
    "* istotne z perspektywy uwydatnienia poszukiwanych informacji\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = '''Termin „post-truth” na tyle zyskał na znaczeniu w opisie rzeczywistości społeczno-politycznej, że w corocznym plebiscycie Oxford Dictionaries redaktorzy uznali go za słowo roku 2016. Argumentowano to m.in. tym, że termin „post-prawda”, używany coraz powszechniej w różnego rodzaju komentarzach politycznych i ważnych publikacjach, przestał mieć znaczenie peryferyjne, stając się terminem samodzielnym, niewymagającym dodatkowego wyjaśniania i definiowania.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Termin „post-truth” na tyle zyskał na znaczeniu w opisie rzeczywistości społeczno-politycznej, że w corocznym plebiscycie Oxford Dictionaries redaktorzy uznali go za słowo roku 2016',\n",
       " ' Argumentowano to m',\n",
       " 'in',\n",
       " ' tym, że termin „post-prawda”, używany coraz powszechniej w różnego rodzaju komentarzach politycznych i ważnych publikacjach, przestał mieć znaczenie peryferyjne, stając się terminem samodzielnym, niewymagającym dodatkowego wyjaśniania i definiowania',\n",
       " '\\n']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nietrywialny przykład z języka polskiego\n",
    "\n",
    "* prof. Jan Kowalski obiecł zaliczenia w 1-szym terminie\n",
    "* Koń ciągnie\n",
    "* Nigdy więcej wojny!\n",
    "* Ala ma kota a kot ma mleko\n",
    "\n",
    "zdanie (ang. sentence) vs wypowiedź (ang. utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = \"Ala ma kota a kot ma mleko. Krzyś ma psa, kota, chomika, jaszczurkę i papugę.\"\n",
    "input_2 = \"Wiedźmin rzucił się w jej stronę, w skoku dobywając miecza.\"\n",
    "input_3 = \"Stale ucz się. Im więcej różnych rzeczy wiesz, tym lepiej. Czytaj techniczną książkę raz na kwartał. Nietechniczne też czytaj. Uczestnicz w kursach, odwiedzaj konferencje.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacja\n",
    "\n",
    "podzieleniu analizowanego tekstu na części ``tokeny``\n",
    "\n",
    "``ala``, ``ma``, ``kota``, ``a``, ``kot``, ``ma``, ``mleko``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala',\n",
       " 'ma',\n",
       " 'kota',\n",
       " 'a',\n",
       " 'kot',\n",
       " 'ma',\n",
       " 'mleko.',\n",
       " 'Krzyś',\n",
       " 'ma',\n",
       " 'psa,',\n",
       " 'chomika,',\n",
       " 'jaszczurkę',\n",
       " 'i',\n",
       " 'papugę.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default - space\n",
    "input_1.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from nltk) (4.64.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wiedźmin',\n",
       " 'rzucił',\n",
       " 'się',\n",
       " 'w',\n",
       " 'jej',\n",
       " 'stronę',\n",
       " ',',\n",
       " 'w',\n",
       " 'skoku',\n",
       " 'dobywając',\n",
       " 'miecza',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(input_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni-Gram | Bi-Gram | Tri-Gram | N-Gram\n",
    "\n",
    "Ala ma kota a kot ma mleko\n",
    "\n",
    "```\n",
    "Uni-Gram (1-gram) Ala, ma, kota, a, kot, ma, mleko\n",
    "Bi-Gram (2-gram) Ala ma, ma kota, kota a, a kot, kot ma, ma mleko \n",
    "Tri-Gram (3-gram) Ala ma kota, ma kota a, kota a kot,  a kot ma, kot ma mleko \n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ala', 'ma', 'kota'),\n",
       " ('ma', 'kota', 'a'),\n",
       " ('kota', 'a', 'kot'),\n",
       " ('a', 'kot', 'ma'),\n",
       " ('kot', 'ma', 'mleko'),\n",
       " ('ma', 'mleko', '.'),\n",
       " ('mleko', '.', 'Krzyś'),\n",
       " ('.', 'Krzyś', 'ma'),\n",
       " ('Krzyś', 'ma', 'psa'),\n",
       " ('ma', 'psa', ','),\n",
       " ('psa', ',', 'chomika'),\n",
       " (',', 'chomika', ','),\n",
       " ('chomika', ',', 'jaszczurkę'),\n",
       " (',', 'jaszczurkę', 'i'),\n",
       " ('jaszczurkę', 'i', 'papugę'),\n",
       " ('i', 'papugę', '.')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "list(ngrams(word_tokenize(input_1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala ma kota a kot ma mleko.', 'Krzyś ma psa, chomika, jaszczurkę i papugę.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prof. Jan Kowalski obiecł zaliczenia w 1-szym terminie']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize('prof. Jan Kowalski obiecł zaliczenia w 1-szym terminie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja\n",
    "\n",
    "Upraszczanie do wspólnej wartości. \n",
    "\n",
    "```\n",
    "kot -> kot\n",
    "kota -> kot\n",
    "kotem -> kot\n",
    "jeden -> jeden\n",
    "jedna -> jeden\n",
    "jeden -> 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J60mV44H_AL-"
   },
   "source": [
    "## Stemming\n",
    "bazując na definicji z angielskiej wikipedii jest to proces polegający na wydobyciu z wybranego wyrazu tzw. rdzenia, a więc tej jego części, która jest odporna na odmiany przez przyimki, rodzaje itp.\n",
    "\n",
    "```\n",
    "Wiedźmin -> Wiedźmin\n",
    "rzucił -> rzucił\n",
    "się -> się \n",
    "w -> w \n",
    "jej -> je\n",
    "stronę -> stron\n",
    "w -> w \n",
    "skoku -> skok\n",
    "dobywając -> dobywa\n",
    "miecza -> miecz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoAe73Ct_Mei"
   },
   "source": [
    "## Lematyzacja\n",
    "\n",
    "pojęcie to jest bardzo podobne do powyższego, a oznacza sprowadzenie grupy wyrazów stanowiących odmianę danego zwrotu do wspólnej postaci, umożliwiającej traktowanie ich wszystkich jako te samo słowo.\n",
    "\n",
    "```\n",
    "Wiedźmin -> Wiedźmin\n",
    "rzucił -> rzuca\n",
    "się -> się \n",
    "w -> w \n",
    "jej -> jej\n",
    "stronę -> strona\n",
    "w -> w \n",
    "skoku -> skok\n",
    "dobywając -> dobywa\n",
    "miecza -> miecz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvaqQG0xj5w_"
   },
   "source": [
    "## Oczyszczanie | Przekształcanie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jkanclerz/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BOOKS = pd.read_pickle('var/books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam Mickiewicz\\r\\n\\r\\nDziady. Widowisko, część I\\r\\n\\r\\n\\r\\n\\r\\n/ Prawa strona teatru — Dziewica w samotnym pokoju — na boku ksiąg mnóstwo, fortepiano, okno z lewej strony w pole; na prawej wielkie zwierciadło; świeca gasnąca na stole i księga rozłożona (romans Vale'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOKS['content'][6][:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ą\\r\\nPewna istota, która z oczu cię [nie] traci,\\r\\nI że chce ciebie w ludzkiej nawiedzić postaci,\\r\\nJeżeli to, coś przyrzekł, zachowasz niezłomnie…\\r\\n\\r\\n\\r\\nGUSTAW\\r\\n\\r\\nPrzebóg! co to ma znaczyć?… Nie zbliżaj się do mnie!\\r\\n\\r\\nI na tym się rękopis kończy\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n-----\\r\\nTa lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\\r\\nWersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/dziady-dziady-widowisko-czesc-i.\\r\\n\\r\\nUtwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\\r\\n\\r\\nWszystkie zasoby Wolnych Lektur możesz swobodnie wykorzystywać, publikować i rozpowszechniać pod warunkiem zachowania warunków licencji i zgodnie z Zasadami wykorzystania Wolnych Lektur.\\r\\nTen utwór jest w domenie publicznej.\\r\\nWszystkie materiały dodatkowe (przypisy, motywy literackie) są udostępnione na Licencji Wolnej Sztuki 1.3: https://artlibre.org/licence/lal/pl/\\r\\nFundacja Nowoczesna Polska zastrzega sobie prawa do wydania krytycznego zgodnie z art. Art.99(2) Ustawy o prawach autorskich i prawach pokrewnych.\\r\\nWykorzystując zasoby z Wolnych Lektur, należy pamiętać o zapisach licencji oraz zasadach, które spisaliśmy w Zasadach wykorzystania Wolnych Lektur: https://wolnelektury.pl/info/zasady-wykorzystania/\\r\\nZapoznaj się z nimi, zanim udostępnisz dalej nasze książki.\\r\\n\\r\\nTekst opracowany na podstawie: Adam Mickiewicz, Dziady cz. 1-4, wyd. Czytelnik, Warszawa 1974\\r\\n\\r\\nWydawca: Fundacja Nowoczesna Polska\\r\\n\\r\\nPublikacja zrealizowana w ramach projektu Wolne Lektury (http://wolnelektury.pl). Reprodukcja cyfrowa wykonana przez Bibliotekę Narodową z egzemplarza pochodzącego ze zbiorów BN.\\r\\n\\r\\nOpracowanie redakcyjne i przypisy: Stanisław Pigoń, Aleksandra Sekuła, Olga Sutkowska.\\r'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOKS['content'][6][-1800:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wolnelektury.pl/media/book/txt/dziady-dziady-widowisko-czesc-i.txt\n",
    "\n",
    "```\n",
    "-----\n",
    "Ta lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\n",
    "Wersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/dziady-dziady-widowisko-czesc-i.\n",
    "\n",
    "Utwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = '''\n",
    "Adam Mickiewicz\\r\\n\\r\\nDziady.\n",
    "\n",
    "ISBN 978-83-288-2972-5\n",
    "Widowisko, część I\\r\\n\\r\\n\\r\\n\\r\\n/ Prawa strona teatru — Dziewica w samotnym pokoju — na boku ksiąg mnóstwo, fortepiano, okno z lewej strony w pole; na prawej wielkie zwierciadło; świeca gasnąca na stole i księga rozłożona (romans Vale\n",
    "----- Ta lektura, podobnie jak tysiące innych, dostępna jest na stronie wolnelektury.pl.\n",
    "Wersja lektury w opracowaniu merytorycznym i krytycznym (przypisy i motywy) dostępna jest na stronie http://wolnelektury.pl/katalog/lektura/dziady-dziady-widowisko-czesc-i.\n",
    "\n",
    "Utwór opracowany został w ramach projektu Wolne Lektury przez fundację Nowoczesna Polska.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "9WT2qseWj8OR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"^.*\\n\",\"\", text) \n",
    "    text = re.sub(r\"ISBN.*[1-9\\-]{16,20}\",\"\", text, flags=re.IGNORECASE) \n",
    "    \n",
    "    text = re.sub(u\"[ \\n]+\", \" \", text) # newlines -> spaces\n",
    "    text = re.sub(u\"[ \\r]+\", \" \", text) # \\r -> spaces\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"----- Ta lektura.*\",\"\", text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "assert ('\\n' not in preprocess_text(test_text))\n",
    "assert ('\\r' not in preprocess_text(test_text))\n",
    "assert ('  ' not in preprocess_text(test_text))\n",
    "assert ('Ta lektura,' not in preprocess_text(test_text))\n",
    "assert ('ISBN' not in preprocess_text(test_text))\n",
    "assert ('2972-5' not in preprocess_text(test_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "VLrSz4zRk-ob",
    "outputId": "1ac33858-8aeb-419e-e313-025ffdbb3d8b"
   },
   "outputs": [],
   "source": [
    "test_text = preprocess_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam Mickiewicz Dziady. Widowisko, część I / Prawa strona teatru — Dziewica w samotnym pokoju — na boku ksiąg mnóstwo, fortepiano, okno z lewej strony w pole; na prawej wielkie zwierciadło; świeca gasnąca na stole i księga rozłożona (romans Vale '"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "E3oMZ2fwnIge"
   },
   "outputs": [],
   "source": [
    "def split_to_sentences(text):\n",
    "  return [re.sub(r\"^ \",\"\",l) for l in re.split('\\.|,|\\?|!|:', text)]\n",
    "\n",
    "assert(['hello world', \"Hello John\"] == split_to_sentences(\"hello world! Hello John\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4CjN7SjVeg"
   },
   "source": [
    "### interpunkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xWaegBkeh1TM",
    "outputId": "88bcbd8f-1731-48e2-f366-aeb35d48d7c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mIxN8jAlifwT"
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "Y5y_YgrCiloW"
   },
   "outputs": [],
   "source": [
    "assert(remove_punct(\"hello, world!\") == \"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam Mickiewicz Dziady Widowisko część I  Prawa strona teatru — Dziewica w samotnym pokoju — na boku ksiąg mnóstwo fortepiano okno z lewej strony w pole na prawej wielkie zwierciadło świeca gasnąca na stole i księga rozłożona romans Vale '"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYvEZdESxGjc"
   },
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "_ZGWOBrhxeUm"
   },
   "outputs": [],
   "source": [
    "stop_words = (requests\n",
    "         .get('https://raw.githubusercontent.com/bieli/stopwords/master/polish.stopwords.txt')\n",
    "         .text\n",
    "         .split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjmr6VLHxi36",
    "outputId": "e2f02f0e-d480-4091-94b3-5ce9a5bcaf1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'alez', 'ależ']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "aeCZwUwPxEUA"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "  return \" \".join([word for word in text.split(' ') if word not in stop_words])\n",
    "\n",
    "assert \"Cześć czołem\" == remove_stop_words(\"Cześć i czołem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>zeromski-oko-za-oko.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nOko za oko\\r\\n\\r\\nISBN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>wszystko-i-nic.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nWszystko i nic\\r\\n\\r\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>zeromski-rozdziobia-nas-kruki-wrony.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nRozdzióbią nas kruki, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>silaczka.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nSiłaczka\\r\\n\\r\\nISBN 97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>syzyfowe-prace.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nSyzyfowe prace\\r\\n\\r\\nI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                 filename  \\\n",
       "0  Zeromski                  zeromski-oko-za-oko.txt   \n",
       "1  Zeromski                       wszystko-i-nic.txt   \n",
       "2  Zeromski  zeromski-rozdziobia-nas-kruki-wrony.txt   \n",
       "3  Zeromski                             silaczka.txt   \n",
       "4  Zeromski                       syzyfowe-prace.txt   \n",
       "\n",
       "                                             content  \n",
       "0  Stefan Żeromski\\r\\n\\r\\nOko za oko\\r\\n\\r\\nISBN ...  \n",
       "1  Stefan Żeromski\\r\\n\\r\\nWszystko i nic\\r\\n\\r\\nI...  \n",
       "2  Stefan Żeromski\\r\\n\\r\\nRozdzióbią nas kruki, w...  \n",
       "3  Stefan Żeromski\\r\\n\\r\\nSiłaczka\\r\\n\\r\\nISBN 97...  \n",
       "4  Stefan Żeromski\\r\\n\\r\\nSyzyfowe prace\\r\\n\\r\\nI...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOKS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "HS_gsLONit3p"
   },
   "outputs": [],
   "source": [
    "BOOKS['content_txt'] = (BOOKS.content\n",
    "                             .apply(preprocess_text)\n",
    "                             .apply(lambda s: s.lower())\n",
    "                             .apply(remove_stop_words)\n",
    "                             .apply(sent_tokenize)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(sentence):\n",
    "    sentence = remove_punct(sentence)\n",
    "    sentence.replace(\"—\", \"\")\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOKS['sentences_clean'] = BOOKS.content_txt.apply(lambda sentences: list(map(clean_sentences, sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "      <th>content_txt</th>\n",
       "      <th>sentences_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>zeromski-oko-za-oko.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nOko za oko\\r\\n\\r\\nISBN ...</td>\n",
       "      <td>[oko oko zawiadowca stacji trebizondów wielki ...</td>\n",
       "      <td>[oko oko zawiadowca stacji trebizondów wielki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>wszystko-i-nic.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nWszystko i nic\\r\\n\\r\\nI...</td>\n",
       "      <td>[ledwie drzwi zamknęły olbromscy, — rafał syn ...</td>\n",
       "      <td>[ledwie drzwi zamknęły olbromscy — rafał syn j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>zeromski-rozdziobia-nas-kruki-wrony.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nRozdzióbią nas kruki, w...</td>\n",
       "      <td>[rozdzióbią kruki, wrony… żywy promień zdołał ...</td>\n",
       "      <td>[rozdzióbią kruki wrony… żywy promień zdołał p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>silaczka.txt</td>\n",
       "      <td>Stefan Żeromski\\r\\n\\r\\nSiłaczka\\r\\n\\r\\nISBN 97...</td>\n",
       "      <td>[siłaczka nienajlepszym humorze powrócił domu ...</td>\n",
       "      <td>[siłaczka nienajlepszym humorze powrócił domu ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                 filename  \\\n",
       "0  Zeromski                  zeromski-oko-za-oko.txt   \n",
       "1  Zeromski                       wszystko-i-nic.txt   \n",
       "2  Zeromski  zeromski-rozdziobia-nas-kruki-wrony.txt   \n",
       "3  Zeromski                             silaczka.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  Stefan Żeromski\\r\\n\\r\\nOko za oko\\r\\n\\r\\nISBN ...   \n",
       "1  Stefan Żeromski\\r\\n\\r\\nWszystko i nic\\r\\n\\r\\nI...   \n",
       "2  Stefan Żeromski\\r\\n\\r\\nRozdzióbią nas kruki, w...   \n",
       "3  Stefan Żeromski\\r\\n\\r\\nSiłaczka\\r\\n\\r\\nISBN 97...   \n",
       "\n",
       "                                         content_txt  \\\n",
       "0  [oko oko zawiadowca stacji trebizondów wielki ...   \n",
       "1  [ledwie drzwi zamknęły olbromscy, — rafał syn ...   \n",
       "2  [rozdzióbią kruki, wrony… żywy promień zdołał ...   \n",
       "3  [siłaczka nienajlepszym humorze powrócił domu ...   \n",
       "\n",
       "                                     sentences_clean  \n",
       "0  [oko oko zawiadowca stacji trebizondów wielki ...  \n",
       "1  [ledwie drzwi zamknęły olbromscy — rafał syn j...  \n",
       "2  [rozdzióbią kruki wrony… żywy promień zdołał p...  \n",
       "3  [siłaczka nienajlepszym humorze powrócił domu ...  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOKS[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "oMcwYFAzm2tC"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOKS[['author',  'sentences_clean']].explode('sentences_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "b3I0EIskoMAV"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOK_LINES.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "u9B0TQRFpVw2",
    "outputId": "40c299d8-b7d3-4327-9826-b92e883bf84b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentences_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>oko oko zawiadowca stacji trebizondów wielki w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>zgromadzeni dokoła stołu przedstawiciele pewne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>urzędnicy powiatowi wtłoczeni małą kanapę zasu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>geometra drugiej klasy pięścią oczyma wzniesio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zeromski</td>\n",
       "      <td>młody doktor miejscowy czarny chudy sztalugi ż...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                    sentences_clean\n",
       "0  Zeromski  oko oko zawiadowca stacji trebizondów wielki w...\n",
       "1  Zeromski  zgromadzeni dokoła stołu przedstawiciele pewne...\n",
       "2  Zeromski  urzędnicy powiatowi wtłoczeni małą kanapę zasu...\n",
       "3  Zeromski  geometra drugiej klasy pięścią oczyma wzniesio...\n",
       "4  Zeromski  młody doktor miejscowy czarny chudy sztalugi ż..."
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOK_LINES.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zK9ml_J4pkVF",
    "outputId": "2be4eacc-c2f4-4965-9814-52dbadf827dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mickiewicz</th>\n",
       "      <td>4678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orzeszkowa</th>\n",
       "      <td>21437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prus</th>\n",
       "      <td>25648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reymont</th>\n",
       "      <td>23197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sienkiewicz</th>\n",
       "      <td>38191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeromski</th>\n",
       "      <td>6311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentences_clean\n",
       "author                      \n",
       "Mickiewicz              4678\n",
       "Orzeszkowa             21437\n",
       "Prus                   25648\n",
       "Reymont                23197\n",
       "Sienkiewicz            38191\n",
       "Zeromski                6311"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOK_LINES.groupby('author').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK1jmVyUp3HU"
   },
   "source": [
    "Duża różnica w elementach danej klasy!! Może mieć wpływ na rezultaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "6pWHWKiFpxWS"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES['words'] = BOOK_LINES.sentences_clean.apply(lambda s: len(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "PRVIqEdOsSXU",
    "outputId": "fd7c0d93-3b2a-493d-9a50-07b0391fe621"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mickiewicz</th>\n",
       "      <td>4678.0</td>\n",
       "      <td>11.845019</td>\n",
       "      <td>10.179747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orzeszkowa</th>\n",
       "      <td>21437.0</td>\n",
       "      <td>12.990624</td>\n",
       "      <td>11.369117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prus</th>\n",
       "      <td>25648.0</td>\n",
       "      <td>9.680170</td>\n",
       "      <td>7.651949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reymont</th>\n",
       "      <td>23197.0</td>\n",
       "      <td>11.121179</td>\n",
       "      <td>12.415336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sienkiewicz</th>\n",
       "      <td>38191.0</td>\n",
       "      <td>9.333613</td>\n",
       "      <td>7.722366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeromski</th>\n",
       "      <td>6311.0</td>\n",
       "      <td>10.743622</td>\n",
       "      <td>7.873517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std  min  25%   50%   75%    max\n",
       "author                                                                 \n",
       "Mickiewicz    4678.0  11.845019  10.179747  1.0  4.0   9.0  16.0   95.0\n",
       "Orzeszkowa   21437.0  12.990624  11.369117  1.0  4.0  10.0  18.0  146.0\n",
       "Prus         25648.0   9.680170   7.651949  1.0  4.0   8.0  12.0  107.0\n",
       "Reymont      23197.0  11.121179  12.415336  1.0  4.0   7.0  14.0  209.0\n",
       "Sienkiewicz  38191.0   9.333613   7.722366  1.0  4.0   7.0  13.0  123.0\n",
       "Zeromski      6311.0  10.743622   7.873517  1.0  5.0   9.0  14.0   70.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOK_LINES.groupby('author')['words'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "zSphnG-Bs5uN"
   },
   "outputs": [],
   "source": [
    "BOOK_LINES = BOOK_LINES[BOOK_LINES['words'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9votvf7asmzG",
    "outputId": "91599880-89b8-45a8-f2f8-01d4d78952cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Mickiewicz     40.0\n",
       "Orzeszkowa     44.0\n",
       "Prus           32.0\n",
       "Reymont        48.0\n",
       "Sienkiewicz    31.0\n",
       "Zeromski       33.0\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOK_LINES.groupby('author')['words'].quantile(0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zJXtgj4vsom-",
    "outputId": "29238dcb-bfaa-4751-a20c-5b6908ad2198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mickiewicz</th>\n",
       "      <td>4678.0</td>\n",
       "      <td>11.845019</td>\n",
       "      <td>10.179747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orzeszkowa</th>\n",
       "      <td>21437.0</td>\n",
       "      <td>12.990624</td>\n",
       "      <td>11.369117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prus</th>\n",
       "      <td>25648.0</td>\n",
       "      <td>9.680170</td>\n",
       "      <td>7.651949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reymont</th>\n",
       "      <td>23197.0</td>\n",
       "      <td>11.121179</td>\n",
       "      <td>12.415336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sienkiewicz</th>\n",
       "      <td>38191.0</td>\n",
       "      <td>9.333613</td>\n",
       "      <td>7.722366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeromski</th>\n",
       "      <td>6311.0</td>\n",
       "      <td>10.743622</td>\n",
       "      <td>7.873517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std  min  25%   50%   75%    max\n",
       "author                                                                 \n",
       "Mickiewicz    4678.0  11.845019  10.179747  1.0  4.0   9.0  16.0   95.0\n",
       "Orzeszkowa   21437.0  12.990624  11.369117  1.0  4.0  10.0  18.0  146.0\n",
       "Prus         25648.0   9.680170   7.651949  1.0  4.0   8.0  12.0  107.0\n",
       "Reymont      23197.0  11.121179  12.415336  1.0  4.0   7.0  14.0  209.0\n",
       "Sienkiewicz  38191.0   9.333613   7.722366  1.0  4.0   7.0  13.0  123.0\n",
       "Zeromski      6311.0  10.743622   7.873517  1.0  5.0   9.0  14.0   70.0"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOOK_LINES.groupby('author')['words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_together = \" \".join(BOOK_LINES[BOOK_LINES.author == 'Mickiewicz'].sentences_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.2.2.tar.gz (220 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/site-packages (from wordcloud) (1.24.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (from wordcloud) (3.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jkanclerz/Library/Python/3.11/lib/python/site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jkanclerz/Library/Python/3.11/lib/python/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-13-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/wordcloud_cli.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/_version.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/__init__.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/tokenization.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/wordcloud.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/color_from_image.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/__main__.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/stopwords -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/DroidSansMono.ttf -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m UPDATING build/lib.macosx-13-x86_64-cpython-311/wordcloud/_version.py\n",
      "  \u001b[31m   \u001b[0m set build/lib.macosx-13-x86_64-cpython-311/wordcloud/_version.py to '1.8.2.2'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'wordcloud.query_integral_image' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-13-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c wordcloud/query_integral_image.c -o build/temp.macosx-13-x86_64-cpython-311/wordcloud/query_integral_image.o\n",
      "  \u001b[31m   \u001b[0m wordcloud/query_integral_image.c:196:12: fatal error: 'longintrepr.h' file not found\n",
      "  \u001b[31m   \u001b[0m   #include \"longintrepr.h\"\n",
      "  \u001b[31m   \u001b[0m            ^~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for wordcloud\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for wordcloud\n",
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "  Running setup.py install for wordcloud ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for wordcloud\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[29 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /usr/local/lib/python3.11/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-13-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/wordcloud_cli.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/_version.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/__init__.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/tokenization.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/wordcloud.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/color_from_image.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/__main__.py -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/stopwords -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m copying wordcloud/DroidSansMono.ttf -> build/lib.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m UPDATING build/lib.macosx-13-x86_64-cpython-311/wordcloud/_version.py\n",
      "  \u001b[31m   \u001b[0m set build/lib.macosx-13-x86_64-cpython-311/wordcloud/_version.py to '1.8.2.2'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'wordcloud.query_integral_image' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-13-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-13-x86_64-cpython-311/wordcloud\n",
      "  \u001b[31m   \u001b[0m clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX13.sdk -I/usr/local/opt/python@3.11/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c wordcloud/query_integral_image.c -o build/temp.macosx-13-x86_64-cpython-311/wordcloud/query_integral_image.o\n",
      "  \u001b[31m   \u001b[0m wordcloud/query_integral_image.c:196:12: fatal error: 'longintrepr.h' file not found\n",
      "  \u001b[31m   \u001b[0m   #include \"longintrepr.h\"\n",
      "  \u001b[31m   \u001b[0m            ^~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m wordcloud\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m WordCloud,STOPWORDS\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width = 400, height = 400, \n",
    "                      background_color = 'black', \n",
    "                      min_font_size = 5,\n",
    "                      stop_words=stop_words,\n",
    "                      max_words=1000,\n",
    "                      collocations=False).generate(\"Ala ma kota a kot ma mleko\")\n",
    "\n",
    "plt.figure(figsize = (12, 12), facecolor = 'lavender')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 2) \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Eksploracyjna_analiza_dokumentów_tekstowych.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
