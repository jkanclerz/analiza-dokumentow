{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhkQMwrapyVx"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/analiza-dokumentow/blob/main/20--text-to-numeric.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuWu_NR1pzrN"
   },
   "source": [
    "# Analiza dokumentów tekstowych\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8j_eVFyvhbE"
   },
   "source": [
    "# Reprezentacja numeryczna\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "https://neptune.ai/blog/vectorization-techniques-in-nlp-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.matemaks.pl/wektory.html\n",
    "https://pl.akinator.com/game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Features = namedtuple(\"Feature\", [\"hair\", \"fat\", \"slim\", \"short\", \"tall\", \"like_honey\", \"live_in_forest\"])\n",
    "\n",
    "kubus = Features(0,1,0,1,0,1,1)\n",
    "prosiaczek = Features(0,0,1,1,0,0,1)\n",
    "osiol = Features(1,1,0,0,0,0,1)\n",
    "\n",
    "answers = Features(1,1,0,0,1,1,1)\n",
    "\n",
    "#[yes, probably_yes, idk, probably_no, no] = [-1, -0.5, 0, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXBR3ZHwvkrY"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3Ty1g4lwZ73"
   },
   "source": [
    "## Bag of words\n",
    "Pozwala reprezentować dane tekstowe jako wektor cech(ang. feature vector). Reprezentacja bag-of-words jest niezwykle prosta, sprowadza się do 2 kroków. 1. Stworzenie słownika unikalnych wyrazów - zbiór wyrazów z całej kolekcji dokumentów 2. Stworzenie reprezentacji wektorowej dla każdego z dokumentów zawierającej częstość wystąpień dla poszczególnych wyrazów\n",
    "\n",
    "Jako, że pojedyńczy dokument zawiera wyłącznie mały wycinek z całego zbioru dostępnych wyrazów, wektor cech zawiera głównie 0. Często nazywany rzadkim (ang. sparse vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6o95OBv8wb9B"
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Care About Your Craft\",\n",
    "    \"Make Quality a Requirements Issue\",\n",
    "    \"Don't Repeat Yourself\",\n",
    "    \"Always Design for Concurrency\",\n",
    "    \"Sign Your Work\",\n",
    "    \"Refactor Early, Refactor Often\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0_qWMgdwfCs"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3AhX2QJwhIK"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(documents)\n",
    "X = cv.transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "5A-vAhg0wiZT",
    "outputId": "86a56aad-6474-44cc-d2f4-b48c4e6fa732"
   },
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(X.toarray(), columns=cv.get_feature_names_out())\n",
    "display(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gra6iA0RwqHB"
   },
   "source": [
    "Transformacja pozwoliła uzyskać strukturę w której każdy wiersz reprezentuje dokument, każda kolumna określa częstość wystąpienia danego tokenu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBWc0Rakwrtv"
   },
   "source": [
    "## Wektor częstości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "ufiyQ6xuwxYE",
    "outputId": "955c7e3c-1518-4d4a-beff-62586234cc48"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=False)\n",
    "cv.fit(documents)\n",
    "X = cv.transform(documents)\n",
    "DF = pd.DataFrame(X.toarray(), columns=cv.get_feature_names_out())\n",
    "display(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01t9yOA3yarY"
   },
   "source": [
    "### zalety\n",
    "+ Jest prostą numeryczną reprezentacją danych tekstowych.\n",
    "\n",
    "### wady\n",
    "\n",
    "- Problem stanowi rozmiar wektora który jest równy długości całego słownika.\n",
    "- Nie uwzględnia relacji pomiędzy semantyką wyrazów\n",
    "- relacje pomiędzy słowami - rózne interpretacje\n",
    "- znaczenie – te same słowa różne znaczenie\n",
    "- metafory, tautologie, ironie\n",
    "- znaki specialne\n",
    "- homonimy - to samo brzmienie inne znaczenia\n",
    "- synonimy, idiomy\n",
    "- 150k słów w słowniku\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIX4wxk4y6eq"
   },
   "source": [
    "## Ważony wektor częstości\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm3jg0VZzV6h"
   },
   "source": [
    "TF-IDF Term Frequency - Inverse Document Frequency pozwala uzyskać wartość określającą istotność danego tokenu w kontekście całego dokumentu. \n",
    "Wartość częstości (TF) nie uwzględnia różnicy w wartości informacyjnej jaką niosą ze sobą poszczególne wyrazy.\n",
    "IDF - pozwala tą różnicę uchwycić.\n",
    "\n",
    "Innymi słowy metodad TF-IDF pozwala wzmocnić znaczenie tokenu wraz ze wzrostem ilości wystąpień w dokumencie. Jednocześnie niwelując efekt wzmocnienia jeżeli dany token występuje równie często w pozostałych dokumentach stanowiących korpus.\n",
    "\n",
    "Wartość tf-idf może być policzona przez mnożenie wartości tf oraz idf\n",
    "\n",
    "$$ TfIdf(t,d) = tf(t,d)*idf(t,d)$$\n",
    "\n",
    "\n",
    "$tf(t,d)$ jest częstością występowania tokenu w dokumencie\n",
    "$idf(t,d)$ obliczany jest wg wzoru\n",
    "\n",
    "$$ idf(t,d) = log\\frac{n_d}{1+df(d,t)}$$\n",
    "$n_d$ - liczba wystąpień w korpusie\n",
    "\n",
    "$df(d,t)$ - liczba dokumentów gdzie występuje token t\n",
    "\n",
    "$1$ - stała 1 jest opcjonalna, niemniej pozwala uzyskać niezerowe wartości dla tokenów występujących we wszystkich dokumentach\n",
    "\n",
    "\n",
    "Implementacja TF-IDF w scikit-learn różni się jednak od powyższej definicji jest liczony następująco:\n",
    "$$ TfIdf(t,d) = tf(t,d)*(idf(t,d) + 1)$$\n",
    "$$ idf(t,d) = log\\frac{1 + n_d}{1+df(d,t)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "fuNXnrDKy_2s",
    "outputId": "9455ebbe-0168-491a-d824-1f32303937a3"
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Hey you, Test Early. Test Often. Test Automatically!\",\n",
    "    \"Hey you, Refactor Early, Refactor Often, Just as you might!\",\n",
    "    \"Hey you, Abstractions Live Longer than Details\",\n",
    "    \"Hey you, Use Saboteurs to Test Your Testing\",\n",
    "    \"Hey you, keep Knowledge in Plain Text\",\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tdif = TfidfVectorizer()\n",
    "X = tdif.fit(documents)\n",
    "X = tdif.transform(documents)\n",
    "DF = pd.DataFrame(X.toarray(), columns=tdif.get_feature_names_out())\n",
    "display(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDo8ha8HzqVz"
   },
   "source": [
    "### zalety\n",
    "\n",
    "* wielkość dokumentu nie ma wpływu wartość, tfifd która jest normalizowana\n",
    "* uwzględnia różnice w znaczeniu tokenów dla znaczenia dokumentu\n",
    "\n",
    "### wady\n",
    "\n",
    "- Nie uwzględnia relacji pomiędzy semantyką wyrazów\n",
    "- relacje pomiędzy słowami - rózne interpretacje\n",
    "- znaczenie – te same słowa różne znaczenie\n",
    "- homonimy - to samo brzmienie inne znaczenia\n",
    "- ignoruje kolejność wyrazów w dokumencie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v1Cknuf0Jmk"
   },
   "source": [
    "## Wektory - odległość\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html\n",
    "\n",
    "### Podobieństwo wektorów / odległość kosinusowa\n",
    "\n",
    "Jest metryką pozwalającą zmierzyć jak 2 wektory są podobne względem siebie. Wartość otrzymujemy obliczając wartość kosinusa konta pomiędzy wektorami w przestrzeni. Odległosć kosinusowa pozwala zniwelować wartości wynikające z położenia wektorów w przestrzeni, zachowując interpretowalną statystykę podobieństwa. Zakres wartości (0,1)\n",
    "\n",
    "\n",
    "\n",
    "![cosine](http://blog.jkan.pl/images/cosine-distance.svg)\n",
    "\n",
    "$ A = (3,3)$\n",
    "$ B = (5,2)$\n",
    "$ C = (5,0.5)$\n",
    "\n",
    "$$Cos\\theta = \\frac{\\vec{a} * \\vec{b}}{||\\vec{a}|| ||\\vec{b}||} = \\frac{\\sum_1^n a_ib_i}{\\sqrt{\\sum_1^na_i^2} * \\sqrt{\\sum_1^nb_i^2}}$$\n",
    "$$Cos\\theta = \\frac{15 + 6}{\\sqrt{18} * \\sqrt{29}}$$\n",
    "$$Cos\\theta = 0,9191$$\n",
    "\n",
    "$$cos(90) = 0$$\n",
    "$$cos(0) = 1$$\n",
    "Kosunius przyjmuje wartość ``0`` dla wektorów prostopadłych (ortogonalnych) i wartość ``1`` dla wektorów równoległych. Im wartość kosinusa bliższa ``1`` tym mniejszy kont pomiędzy wektorami\n",
    "\n",
    "Wykorzystując metodę cosine z ``scipy.spatial.distance`` musimy pamiętać o przekształceniu wg wzoru: \n",
    "\n",
    "$$Cosine Similarity = 1 − Cosine Distance$$\n",
    "\n",
    "Oczekujemy że $podobieństwo(A,B) > podobieństwo(A,C)$ ponieważ kąt pomiędzy wektorami A,B jest mniejszy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "A = (3,3)\n",
    "B = (5,2)\n",
    "C = (5,0.5)\n",
    "cosine(A, B), cosine(A, C), cosine(A ,A), cosine((0,1), (1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## similarity 1 - cosine\n",
    "1 - cosine(kubus,kubus) # maxymalne podobieństwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHvOciRj0syP",
    "outputId": "4d71d51e-ac20-4895-cd8b-7a6355558768"
   },
   "outputs": [],
   "source": [
    "A = (1,0,0)\n",
    "B = (0,1,0)\n",
    "1 - cosine(A,B)\n",
    "0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY-fJjmv005t",
    "outputId": "009dfe4f-e573-40ba-f665-0dc255be4b57"
   },
   "outputs": [],
   "source": [
    "A = (1,0,0)\n",
    "1 - cosine(A,A)\n",
    "1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1etkjFlr02hK"
   },
   "outputs": [],
   "source": [
    "characters = [('kubus', kubus), ('prosiaczek', prosiaczek), ('osiol', osiol)]\n",
    "\n",
    "akinator = list(map(lambda vec: (vec[0], 1 - cosine(vec[1], answers)), characters))\n",
    "\n",
    "sorted(akinator, key=lambda vec: vec[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_the_game(answers: Features) -> str:\n",
    "    characters = [('kubus', kubus), ('prosiaczek', prosiaczek), ('osiol', osiol)]\n",
    "    akinator = list(map(lambda vec: (vec[0], 1 - cosine(vec[1], answers)), characters))\n",
    "    guess = sorted(akinator, key=lambda vec: vec[1], reverse=True)\n",
    "    return guess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_the_game(Features(0,0,1,1,0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsZ0s3RP0-ju"
   },
   "source": [
    "## Inne metryki\n",
    "* Manhattan distance\n",
    "* Euclidean distance\n",
    "* Minkowski distance\n",
    "* Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sFaKoXm1Bp-",
    "outputId": "01e3b863-a986-4b00-8dc4-f7c2887465aa"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jaccard\n",
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cityblock\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "A = (3, 22, 55, 13)\n",
    "B = (1, 12, 40, 5)\n",
    "\n",
    "jaccard(A,B), minkowski(A,B), euclidean(A,B), cityblock(A,B), cosine(A,B)\n",
    "(1.0, 19.82422760159901, 19.82422760159901, 35, 0.008847457489864041)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Eksploracyjna_analiza_dokumentów_tekstowych.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
